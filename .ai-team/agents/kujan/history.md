# Project Context

- **Owner:** bradygaster (bradygaster@users.noreply.github.com)
- **Project:** Squad â€” AI agent teams that grow with your code. Democratizing multi-agent development on GitHub Copilot. Mission: beat the industry to what customers need next.
- **Stack:** Node.js, GitHub Copilot CLI, multi-agent orchestration
- **Created:** 2026-02-07

## Core Context

_Summarized from initial platform assessment and deep onboarding (2026-02-07). Full entries in `history-archive.md`._

- **Squad is already Copilot-native** â€” task tool spawning, filesystem memory, background mode all align with the platform. No fundamental rewrites needed. Stay independent (not a Copilot SDK product) but be best-in-class on Copilot.
- **Filesystem-backed memory is the killer differentiator** â€” git-cloneable, human-readable, and the reliable channel (vs. unreliable response text). Never abandon for SDK abstractions.
- **Inline charter pattern is correct for batch spawns** â€” coordinator inlines charters to eliminate agent tool calls. For single spawns, agent-reads-own is acceptable.
- **Platform constraints**: 128K token context window, `task` tool with `mode: "background"` is the correct spawn pattern, `explore` sub-agent for semantic search, no agent persistence between sessions.
- **Coordinator size (32KB+) is a maintenance concern** â€” instruction-following degrades with prompt length. Subsystem extraction or information density optimization needed.
- **Drop-box pattern is the best lock-free concurrent write pattern** on this platform. Preserve and extend.
- **Key validated patterns**: parallel fan-out by default, eager execution philosophy, Scribe serial spawning (confirmed as friction to fix).

### Session Summaries

- **2026-02-08: Agent Persistence & Latency Analysis (Proposal 007)** â€” **Context:** Brady reported "agents get in the way more than they help" later in sessions. Collaborated with Verbal on a latency reduction proposal.
- **2026-02-08: Portable Squads â€” Platform Feasibility Analysis (Proposal 008)** â€” **Context:** Brady wants users to export squads from one project and import into another, keeping names, personalities, and user meta-knowledge while 
- **2026-02-08: Skills, Platform Feasibility, and v1 Copilot Integration (Proposal 012)** â€” **Context:** Brady hinted at "skills" â€” agents that learn domain expertise across projects. Also needed: complete v1 Copilot experience synthesis comb
- **2026-02-08: P0 Silent Success Bug â€” Diagnosis and Mitigation (Proposal 015)** â€” **Context:** Brady flagged that ~40% of background agents report "did not produce a response" when they actually completed all work. Files written, hi
- **2026-02-09: Proposal 012 Revision â€” Agent Skills Open Standard + MCP Integration** â€” **Context:** Brady clarified that "skills" means Claude-and-Copilot-compliant skills adhering to the Agent Skills Open Standard (agentskills.io). Also
- **2026-02-09: Platform Timeout Best Practices Documented** â€” **Context:** Brady discovered that the `read_agent` default timeout of 30s was causing the platform to abandon agents mid-work â€” reporting "no respons
- **2026-02-09: Proposal 015 Mitigation Verification Audit** â€” **Context:** Brady requested all agents verify their mitigations are in place for the P0 silent success bug. As the author of Proposal 015, verified a
- **2026-02-09: decisions.md Cleanup â€” Heading Levels and Line Endings** â€” **Context:** Audit flagged formatting issues in decisions.md. Tasked with surgical fixes: phantom proposal references, heading level corrections, and 
- **2026-02-09: Platform Feasibility â€” Direct Messaging Interface (Proposal 017)** â€” **Context:** Brady wants to work with his Squad via direct messages (Telegram) when away from the terminal. Requested Dev Tunnels over ngrok. This is 
- **2026-02-09: Human Input Latency and Persistence â€” Platform Analysis** â€” **Context:** Brady described two pain points: (1) latency when typing while agents work â€” messages queue and the experience feels unresponsive, (2) hu
- **2026-02-09: VS Code Parity, Mid-Flight Human Input, and Feedback Optimization** â€” **Context:** Brady asked three platform questions: (1) does Squad work in VS Code, (2) can human input reach running agents, (3) how to optimize feedb
- **2026-02-09: Directive Capture in Coordinator Prompt (Sprint Task 1.6)** â€” **Context:** Brady requested human directive capture â€” when users state preferences, rules, or scope decisions, the coordinator should persist them to
- **2026-02-09: Incoming Queue Platform Assessment** â€” **Context:** Brady asked whether Copilot's built-in TODO capability could serve as an "incoming queue" for user messages â€” capturing requests while ag

## Recent Updates

ðŸ“Œ Team update (2026-02-09): No npm publish â€” GitHub-only distribution. Kobayashi hired as Git & Release Engineer. Release plan (021) filed. Sprint plan 019a amended: item 1.8 cancelled, items 1.11-1.13 added.
ðŸ“Œ Team update (2026-02-08): CI pipeline created â€” GitHub Actions runs tests on push/PR to main/dev. PRs now have automated quality gate. â€” decided by Hockney
ðŸ“Œ Team update (2026-02-08): Coordinator must acknowledge user requests with brief text before spawning agents. Single agent gets a sentence; multi-agent gets a launch table. â€” decided by Verbal
ðŸ“Œ Team update (2026-02-08): Silent success mitigation strengthened in all spawn templates â€” 6-line RESPONSE ORDER block + filesystem-based detection. â€” decided by Verbal
ðŸ“Œ Team update (2026-02-08): Incoming queue architecture direction â€” SQL as hot working layer, filesystem as durable store, team backlog as key feature, agents can clone across worktrees â€” decided by Brady
ðŸ“Œ Team update (2026-02-08): .ai-team/ must NEVER be tracked in git on main. Three-layer protection: .gitignore, package.json files allowlist, .npmignore. â€” decided by Verbal
ðŸ“Œ Team update (2026-02-08): Incoming queue architecture finalized â€” SQL hot layer + filesystem durable store, team backlog as third memory channel, agent cloning ready. â€” decided by Verbal
ðŸ“Œ Team update (2026-02-09): If ask_user returns < 10 characters, treat as ambiguous and re-confirm â€” platform may fabricate default responses from blank input. â€” decided by Brady
ðŸ“Œ Team update (2026-02-09): PR #2 integrated â€” GitHub Issues Mode, PRD Mode, Human Team Members added to coordinator with review fixes (gh CLI detection, post-setup questions, worktree guidance). â€” decided by Fenster
ðŸ“Œ Team update (2026-02-09): Documentation structure formalized â€” docs/ is user-facing only, team-docs/ for internal, .ai-team/ is runtime state. Three-tier separation is permanent. â€” decided by Kobayashi
ðŸ“Œ Team update (2026-02-09): Per-agent model selection designed â€” 4-layer priority (user override â†’ charter â†’ registry â†’ auto-select). Role-to-model mapping: Designerâ†’Opus, Tester/Scribeâ†’Haiku, Lead/Devâ†’Sonnet. â€” decided by Verbal
ðŸ“Œ Team update (2026-02-09): Tiered response modes shipped â€” Direct/Lightweight/Standard/Full modes replace uniform spawn overhead. Agents may now be spawned with lightweight template (no charter/history/decisions reads) for simple tasks. â€” decided by Verbal
ðŸ“Œ Team update (2026-02-09): Skills Phase 1 + Phase 2 shipped â€” agents now read SKILL.md files before working and can write SKILL.md files from real work. Skills live in .ai-team/skills/{name}/SKILL.md. Confidence lifecycle: lowâ†’mediumâ†’high. â€” decided by Verbal
ðŸ“Œ Team update (2026-02-09): Portable Squads consolidated â€” architecture, platform, and experience merged into single decision â€” decided by Keaton, Kujan, Verbal
ðŸ“Œ Team update (2026-02-09): Skills system consolidated â€” open standard with MCP tool declarations, merging 4 independent analyses â€” decided by Kujan, Verbal


ðŸ“Œ Team update (2026-02-09): Preview branch added to release pipeline â€” two-phase workflow: preview then ship. Brady eyeballs preview before anything hits main. â€” decided by Kobayashi

## Learnings

- **2026-02-10: Full Model Catalog Research (Proposal 024a)** â€” Researched and documented all 16 models available via the `task` tool's `model` parameter across 3 providers (Anthropic: 6 models, OpenAI: 9 models, Google: 1 model) and 3 tiers (premium, standard, fast/cheap). Key findings:
  - The platform offers far more diversity than Proposal 024's original 3-model mapping (Opus/Sonnet/Haiku). Brady was right to push back.
  - OpenAI Codex variants (GPT-5.2-Codex, GPT-5.1-Codex-Max) are genuinely strong contenders for code-heavy tasks â€” may outperform Claude Sonnet for pure code generation.
  - Gemini 3 Pro (Preview) offers cognitive diversity value for reviews/audits â€” different training yields different perspectives, which is signal not noise.
  - Provider diversity is a resilience play, not just a quality play. Single-provider dependency is a real operational risk for multi-agent systems.
  - Anthropic remains the safest default family (best instruction following, proven in agent workflows), with OpenAI as specialist for code and Google as specialist for diversity.
  - Opus 4.6 fast mode is an underappreciated option â€” premium quality at reduced latency for time-sensitive decisions (reviewer gates).
  - The expanded role-to-model mapping covers 11 roles Ã— 2 models (default + specialist) with clear switching criteria.
  - Honest about knowledge gaps: Gemini 3 Pro Preview behavior may change, cross-provider prompt portability is untested, exact cost ratios unknown on the platform.
  - Output: `team-docs/proposals/024a-model-catalog.md` â€” reference document for Verbal's selection algorithm (sprint item 4.1).
- **2026-02-10: GitHub API Capabilities Assessment (Proposal 028a)** â€” Empirically tested all GitHub MCP server tools, `gh` CLI commands, and agent access patterns for Issues and Projects management. Key findings:
  - MCP tools are **read-only for Issues** â€” no create/update/close. All writes must go through `gh` CLI.
  - **Zero MCP tools exist for GitHub Projects V2** â€” entire Projects workflow depends on `gh project` commands.
  - `task` and `general-purpose` sub-agents **CAN** access MCP tools AND `gh` CLI â€” they can self-serve GitHub operations without coordinator mediation.
  - `explore` sub-agents have **NO MCP or shell access** â€” local filesystem only (grep/glob/view).
  - GitHub Projects is **blocked by missing token scope** (`project`). Fix: Brady runs `gh auth refresh -s project` once.
  - Current token scopes: `gist`, `read:org`, `repo`, `workflow` â€” sufficient for Issues, insufficient for Projects.
  - Rate limits are generous: 5,000 REST/hour, 5,000 GraphQL/hour, 30 searches/minute. Normal Squad operations use <5% capacity.
  - Only real rate limit risk: Search API (30/min) during batch operations â€” prefer list operations over search.
  - Recommended two-channel pattern: MCP for reads (structured data), `gh` CLI for writes (only option).
  - Full issue lifecycle verified: create â†’ label â†’ comment â†’ close â†’ read back via MCP. All working.
  - Output: `team-docs/proposals/028a-github-api-capabilities.md` and `.ai-team/decisions/inbox/kujan-github-api-assessment.md`.

- **2026-02-10: Async Comms Feasibility Assessment (Proposal 030)** â€” Updated feasibility assessment for async squad communication, superseding Proposal 017. Brady un-deferred this feature to TOP PRIORITY for 0.3.0. Key findings:
  - **CCA-as-squad-member is the breakthrough.** Copilot Coding Agent reads `squad.agent.md` (same file Squad uses as coordinator prompt). Adding CCA guidance to that file gives Brady async work assignment via GitHub Issues + Mobile for ~2-4 hours of prompt engineering. Zero new infrastructure.
  - **CCA + GitHub Issues is async communication through GitHub's own surfaces.** Issue â†’ assign @copilot â†’ CCA works under Squad governance â†’ PR â†’ Brady reviews on phone. Not conversational, but functional async comms with zero build cost.
  - **Copilot SDK confirmed mature enough for Telegram bridge.** Multi-turn, custom tools, model selection, streaming all verified. Nested sessions (task equivalent) remain the UNVERIFIED gate â€” need a 1-day spike.
  - **Connector ranking:** CCA+Issues (ship now, free) > Telegram (ship 0.3.0 if SDK spike passes) > Discord (0.4.0) > GitHub Discussions (fallback) > Teams (0.4.0+, best per-repo but highest build cost) > Slack (0.5.0+).
  - **Per-repo solution varies by platform:** GitHub Issues = native per-repo. Telegram = groups per repo. Teams = channels per repo (best). Discord = channels per repo.
  - **Two-tier MVP recommended:** Tier 1 (CCA guidance, 2-4h, prompt-only) + Tier 2 (Telegram bridge, 8-16h, new code). Ship Tier 1 in 0.3.0 Wave 2 guaranteed; Tier 2 conditional on SDK spike.
  - Output: `team-docs/proposals/030-async-comms-feasibility.md`.

ðŸ“Œ Team update (2026-02-10): v0.3.0 sprint plan approved â€” your model catalog research (024a) and GitHub API assessment (028a) are foundational inputs. â€” decided by Keaton


ðŸ“Œ Team update (2026-02-10): Async squad comms is #1 priority for 0.3.0 â€” update feasibility analysis â€” decided by bradygaster

ðŸ“Œ Team update (2026-02-10): Squad DM (Proposal 017) un-deferred to P0 â€” decided by bradygaster
